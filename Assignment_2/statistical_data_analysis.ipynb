{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "967656af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # SET A:\n",
    "# 1. Write a Python program to find the maximum and minimum value of a given flattened array.\n",
    "# Expected Output:Original flattened array:\n",
    "# [[0 1]\n",
    "# [2 3]]\n",
    "# Maximum value of the above flattened array:3\n",
    "# Minimum value of the above flattened array:0\n",
    "# 2. Write a python program to compute Euclidian Distance between two data points in a dataset. [Hint: Use linalgo.norm function from NumPy]\n",
    "# 3. Create one dataframe of data values. Find out mean, range and IQR for this data.\n",
    "# 4. Write a python program to compute sum of Manhattan distance between all pairs of points.\n",
    "# \n",
    "# 5. Write a NumPy program to compute the histogram of nums against the bins. Sample Output:\n",
    "# nums: [0.5 0.7 1. 1.2 1.3 2.1]\n",
    "# bins: [0 1 2 3]\n",
    "# Result: (array([2, 3, 1], dtype=int64), array([0, 1, 2, 3]))\n",
    "# 6. Create a dataframe for students’ information such name, graduation percentage and age.\n",
    "# Display average age of students, average of graduation percentage. And, also describe all basic statistics of data. (Hint: use describe()). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "040a790c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original flattened array:\n",
      "[[0 1]\n",
      " [2 3]]\n",
      "Maximum value of the above flattened array:\n",
      "3\n",
      "Minimum value of the above flattened array:\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# 1. Write a Python program to find the maximum and minimum value of a given flattened array.\n",
    "\n",
    "import numpy as np\n",
    "a = np.arange(4).reshape((2,2))\n",
    "print(\"Original flattened array:\")\n",
    "print(a)\n",
    "print(\"Maximum value of the above flattened array:\")\n",
    "print(np.amax(a))\n",
    "print(\"Minimum value of the above flattened array:\")\n",
    "print(np.amin(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "549af99a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.23606797749979\n"
     ]
    }
   ],
   "source": [
    "# Write a python program to compute Euclidian Distance between two data points in a dataset. [Hint: Use linalgo.norm function from NumPy]\n",
    "\n",
    "import numpy as np\n",
    " \n",
    "# initializing points in\n",
    "# numpy arrays\n",
    "point1 = np.array((1, 2, 3))\n",
    "point2 = np.array((1, 1, 1))\n",
    " \n",
    "# calculating Euclidean distance\n",
    "# using linalg.norm()\n",
    "dist = np.linalg.norm(point1 - point2)\n",
    " \n",
    "# printing Euclidean distance\n",
    "print(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e282df65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12.25"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Create one dataframe of data values. Find out mean, range and IQR for this data.\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#define array of data\n",
    "data = np.array([14, 19, 20, 22, 24, 26, 27, 30, 30, 31, 36, 38, 44, 47])\n",
    "\n",
    "#calculate interquartile range \n",
    "q3, q1 = np.percentile(data, [75 ,25])\n",
    "iqr = q3 - q1\n",
    "\n",
    "#display interquartile range \n",
    "iqr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5739f137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    29.142857\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data)\n",
    "df.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4aaceae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. Write a python program to compute sum of Manhattan distance between all pairs of points.\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "#create function to calculate Manhattan distance \n",
    "def manhattan(a, b):\n",
    "    return sum(abs(val1-val2) for val1, val2 in zip(a,b))\n",
    " \n",
    "#define vectors\n",
    "A = [2, 4, 4, 6]\n",
    "B = [5, 5, 7, 8]\n",
    "\n",
    "#calculate Manhattan distance between vectors\n",
    "manhattan(A, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f38c5ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nums:  [0.5 0.7 1.  1.2 1.3 2.1]\n",
      "bins:  [0 1 2 3]\n",
      "Result: (array([2, 3, 1], dtype=int64), array([0, 1, 2, 3]))\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 5. Write a NumPy program to compute the histogram of nums against the bins. Sample Output:\n",
    "# nums: [0.5 0.7 1. 1.2 1.3 2.1]\n",
    "# bins: [0 1 2 3]\n",
    "# Result: (array([2, 3, 1], dtype=int64), array([0, 1, 2, 3]))\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "nums = np.array([0.5, 0.7, 1.0, 1.2, 1.3, 2.1])\n",
    "bins = np.array([0, 1, 2, 3])\n",
    "print(\"nums: \",nums)\n",
    "print(\"bins: \",bins)\n",
    "print(\"Result:\", np.histogram(nums, bins))\n",
    "plt.hist(nums, bins=bins)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "14977dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean score for each different student in data frame:\n",
      "<bound method NDFrame._add_numeric_operations.<locals>.mean of a    12.5\n",
      "b     9.0\n",
      "c    16.5\n",
      "d     NaN\n",
      "e     9.0\n",
      "f    20.0\n",
      "g    14.5\n",
      "h     NaN\n",
      "i     8.0\n",
      "j    19.0\n",
      "Name: score, dtype: float64>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>attempts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>10.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>13.562500</td>\n",
       "      <td>1.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.693746</td>\n",
       "      <td>0.875595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.500000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>17.125000</td>\n",
       "      <td>2.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           score   attempts\n",
       "count   8.000000  10.000000\n",
       "mean   13.562500   1.900000\n",
       "std     4.693746   0.875595\n",
       "min     8.000000   1.000000\n",
       "25%     9.000000   1.000000\n",
       "50%    13.500000   2.000000\n",
       "75%    17.125000   2.750000\n",
       "max    20.000000   3.000000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6. Create a dataframe for students’ information such name, graduation percentage and age.\n",
    "# Display average age of students, average of graduation percentage. And, also describe all basic statistics of data. (Hint: use describe()). \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "exam_data  = {'name': ['Anastasia', 'Dima', 'Katherine', 'James', 'Emily', 'Michael', 'Matthew', 'Laura', 'Kevin', 'Jonas'],\n",
    "        'score': [12.5, 9, 16.5, np.nan, 9, 20, 14.5, np.nan, 8, 19],\n",
    "        'attempts': [1, 3, 2, 3, 2, 3, 1, 1, 2, 1],\n",
    "        'qualify': ['yes', 'no', 'yes', 'no', 'no', 'yes', 'yes', 'no', 'no', 'yes']}\n",
    "labels = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j']\n",
    "\n",
    "df = pd.DataFrame(exam_data , index=labels)\n",
    "print(\"\\nMean score for each different student in data frame:\")\n",
    "print(df['score'].mean)\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fe1492a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SET B:\n",
    "# 1. Download iris dataset file. Read this csv file using read_csv() function. Take samples from entire dataset. Display maximum and minimum values of all numeric attributes.\n",
    "# 2. Continue with above dataset, find number of records for each distinct value of class attribute. Consider entire dataset and not the samples.\n",
    "# 3. Display column-wise mean, and median for iris dataset from Q.4 (Hint: Use mean() and median() functions of pandas dataframe. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f6a16a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
      "0            5.1           3.5            1.4           0.2  Iris-setosa\n",
      "1            4.9           3.0            1.4           0.2  Iris-setosa\n",
      "2            4.7           3.2            1.3           0.2  Iris-setosa\n",
      "3            4.6           3.1            1.5           0.2  Iris-setosa\n",
      "4            5.0           3.6            1.4           0.2  Iris-setosa\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SepalLengthCm               7.9\n",
       "SepalWidthCm                4.4\n",
       "PetalLengthCm               6.9\n",
       "PetalWidthCm                2.5\n",
       "Species          Iris-virginica\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\",\n",
    "                 names = ['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm', 'Species'])\n",
    "print(df.head())\n",
    "df.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40f21e0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SepalLengthCm            4.3\n",
       "SepalWidthCm             2.0\n",
       "PetalLengthCm            1.0\n",
       "PetalWidthCm             0.1\n",
       "Species          Iris-setosa\n",
       "dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71cda04c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No.of.unique SepalLengthCm values : 35\n",
      "No.of.unique SepalWidthCm values : 23\n",
      "No.of.unique PetalLengthCm values : 43\n",
      "No.of.unique PetalWidthCm values : 22\n",
      "No.of.unique Species values : 3\n"
     ]
    }
   ],
   "source": [
    "n = len(pd.unique(df['SepalLengthCm']))\n",
    "print(\"No.of.unique SepalLengthCm values :\",n)\n",
    "n1 = len(pd.unique(df['SepalWidthCm']))\n",
    "print(\"No.of.unique SepalWidthCm values :\",n1)\n",
    "n2 = len(pd.unique(df['PetalLengthCm']))\n",
    "print(\"No.of.unique PetalLengthCm values :\",n2)\n",
    "n3 = len(pd.unique(df['PetalWidthCm']))\n",
    "print(\"No.of.unique PetalWidthCm values :\",n3)\n",
    "n4 = len(pd.unique(df['Species']))\n",
    "print(\"No.of.unique Species values :\",n4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "618306e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp/ipykernel_2444/3698961737.py:1: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df.mean()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SepalLengthCm    5.843333\n",
       "SepalWidthCm     3.054000\n",
       "PetalLengthCm    3.758667\n",
       "PetalWidthCm     1.198667\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3fa6b670",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp/ipykernel_2444/530051474.py:1: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df.median()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SepalLengthCm    5.80\n",
       "SepalWidthCm     3.00\n",
       "PetalLengthCm    4.35\n",
       "PetalWidthCm     1.30\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7af48449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # SET C:\n",
    "# 1. Write a python program to find Minkowskii Distance between two points.\n",
    "# 2. Write a Python NumPy program to compute the weighted average along the specified\n",
    "# axis of a given flattened array.\n",
    "# From Wikipedia: The weighted arithmetic mean is similar to an ordinary arithmetic\n",
    "# mean (the most common type of average), except that instead of each of the data points\n",
    "# contributing equally to the final average, some data points contribute more than others.\n",
    "# The notion of weighted mean plays a role in descriptive statistics and also occurs in a\n",
    "# more general form in several other areas of mathematics.\n",
    "# Sample output:\n",
    "# Original flattened array:\n",
    "# [[0 1 2]\n",
    "# [3 4 5]\n",
    "# [6 7 8]]\n",
    "# Weighted average along the specified axis of the above flattened array:\n",
    "# [1.2 4.2 7.2]\n",
    "# 3. Write a NumPy program to compute cross-correlation of two given arrays.\n",
    "# Sample Output:\n",
    "# Original array1:\n",
    "# [0 1 3]\n",
    "# Original array2:\n",
    "# [2 4 5]\n",
    "# Cross-correlation of the said arrays:\n",
    "# [[2.33333333 2.16666667]\n",
    "# [2.16666667 2.33333333]]\n",
    "# 4. Download any dataset from UCI (do not repeat it from set B). Read this csv file using\n",
    "# read_csv() function. Describe the dataset using appropriate function. Display mean\n",
    "# value of numeric attribute. Check any data values are missing or not.\n",
    "# 5. Download nursery dataset from UCI. Split dataset on any one categorical attribute.\n",
    "# Compare the means of each split. (Use groupby)\n",
    "# 6. Create one dataframe with 5 subjects and marks of 10 students for each subject. Find\n",
    "# arithmetic mean, geometric mean, and harmonic mean.\n",
    "# 7. Download any csv file of your choice and display details about data using pandas\n",
    "# profiling. Show stats in HTML form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1c89d466",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Distance is:: 3.144\n"
     ]
    }
   ],
   "source": [
    "# 1. Write a python program to find Minkowskii Distance between two points.\n",
    "\n",
    "from math import *\n",
    "from decimal import Decimal\n",
    "def my_p_root(value, root):\n",
    "   my_root_value = 1 / float(root)\n",
    "   return round (Decimal(value) **\n",
    "   Decimal(my_root_value), 3)\n",
    "def my_minkowski_distance(x, y, p_value):\n",
    "   return (my_p_root(sum(pow(abs(a-b), p_value)\n",
    "      for a, b in zip(x, y)), p_value))\n",
    "# Driver Code\n",
    "vector1 = [0, 2, 3, 4]\n",
    "vector2 = [2, 4, 3, 7]\n",
    "my_position = 5\n",
    "print(\"The Distance is::\",my_minkowski_distance(vector1, vector2, my_position))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eaa6eb6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original flattened array:\n",
      "[[0 1 2]\n",
      " [3 4 5]\n",
      " [6 7 8]]\n",
      "Weighted average along the specified axis of the above flattened array:\n",
      "[1.2 4.2 7.2]\n"
     ]
    }
   ],
   "source": [
    "# 2. Write a Python NumPy program to compute the weighted average along the specified\n",
    "# axis of a given flattened array.\n",
    "# From Wikipedia: The weighted arithmetic mean is similar to an ordinary arithmetic\n",
    "# mean (the most common type of average), except that instead of each of the data points\n",
    "# contributing equally to the final average, some data points contribute more than others.\n",
    "# The notion of weighted mean plays a role in descriptive statistics and also occurs in a\n",
    "# more general form in several other areas of mathematics.\n",
    "# Sample output:\n",
    "# Original flattened array:\n",
    "# [[0 1 2]\n",
    "# [3 4 5]\n",
    "# [6 7 8]]\n",
    "# Weighted average along the specified axis of the above flattened array:\n",
    "# [1.2 4.2 7.2]\n",
    "\n",
    "import numpy as np\n",
    "a = np.arange(9).reshape((3,3))\n",
    "print(\"Original flattened array:\")\n",
    "print(a)\n",
    "print(\"Weighted average along the specified axis of the above flattened array:\")\n",
    "print(np.average(a, axis=1, weights=[1./4, 2./4, 2./4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "21ed7ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Original array1:\n",
      "[0 1 3]\n",
      "\n",
      "Original array1:\n",
      "[2 4 5]\n",
      "\n",
      "Cross-correlation of the said arrays:\n",
      " [[2.33333333 2.16666667]\n",
      " [2.16666667 2.33333333]]\n"
     ]
    }
   ],
   "source": [
    "# 3. Write a NumPy program to compute cross-correlation of two given arrays.\n",
    "# Sample Output:\n",
    "# Original array1:\n",
    "# [0 1 3]\n",
    "# Original array2:\n",
    "# [2 4 5]\n",
    "# Cross-correlation of the said arrays:\n",
    "# [[2.33333333 2.16666667]\n",
    "# [2.16666667 2.33333333]]\n",
    "\n",
    "import numpy as np\n",
    "x = np.array([0, 1, 3])\n",
    "y = np.array([2, 4, 5])\n",
    "print(\"\\nOriginal array1:\")\n",
    "print(x)\n",
    "print(\"\\nOriginal array1:\")\n",
    "print(y)\n",
    "print(\"\\nCross-correlation of the said arrays:\\n\",np.cov(x, y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0078ef28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Newspaper</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>200.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>100.500000</td>\n",
       "      <td>147.042500</td>\n",
       "      <td>23.264000</td>\n",
       "      <td>30.554000</td>\n",
       "      <td>14.022500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>57.879185</td>\n",
       "      <td>85.854236</td>\n",
       "      <td>14.846809</td>\n",
       "      <td>21.778621</td>\n",
       "      <td>5.217457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>1.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>50.750000</td>\n",
       "      <td>74.375000</td>\n",
       "      <td>9.975000</td>\n",
       "      <td>12.750000</td>\n",
       "      <td>10.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>100.500000</td>\n",
       "      <td>149.750000</td>\n",
       "      <td>22.900000</td>\n",
       "      <td>25.750000</td>\n",
       "      <td>12.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>150.250000</td>\n",
       "      <td>218.825000</td>\n",
       "      <td>36.525000</td>\n",
       "      <td>45.100000</td>\n",
       "      <td>17.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>200.000000</td>\n",
       "      <td>296.400000</td>\n",
       "      <td>49.600000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>27.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0          TV       Radio   Newspaper       Sales\n",
       "count  200.000000  200.000000  200.000000  200.000000  200.000000\n",
       "mean   100.500000  147.042500   23.264000   30.554000   14.022500\n",
       "std     57.879185   85.854236   14.846809   21.778621    5.217457\n",
       "min      1.000000    0.700000    0.000000    0.300000    1.600000\n",
       "25%     50.750000   74.375000    9.975000   12.750000   10.375000\n",
       "50%    100.500000  149.750000   22.900000   25.750000   12.900000\n",
       "75%    150.250000  218.825000   36.525000   45.100000   17.400000\n",
       "max    200.000000  296.400000   49.600000  114.000000   27.000000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. Download any dataset from UCI (do not repeat it from set B). Read this csv file using\n",
    "# read_csv() function. Describe the dataset using appropriate function. Display mean\n",
    "# value of numeric attribute. Check any data values are missing or not.\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\"C:\\\\Users\\\\Lenovo\\\\Desktop\\\\Languages\\\\Data Science\\\\Data sets\\\\Advertising.csv\")\n",
    "df\n",
    "\n",
    "\n",
    "df.isnull()\n",
    "\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "03785f93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp/ipykernel_2444/2148679764.py:16: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df.mean()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "74.81660373209458"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6. Create one dataframe with 5 subjects and marks of 10 students for each subject. Find arithmetic mean, geometric mean, and harmonic mean. \n",
    "\n",
    "from scipy.stats import hmean\n",
    "import pandas as pd\n",
    "# define the dataset\n",
    "\n",
    "data ={'StudentName': ['rama','shama','radha','dhara','arti','priti','sapna','komal','rima','neha'],\n",
    "       'Maths': [56,67,78,89,90,56,67,78,89,90],\n",
    "      'English': [77,88,77,88,99,66,45,88,77,77],\n",
    "      'Science' : [66,88,99,88,77,66,88,99,88,77],\n",
    "       'History' : [77,88,77,88,99,66,45,88,77,77],\n",
    "       'Geography' : [77,88,77,88,99,66,45,88,77,77]\n",
    "      }\n",
    "df = pd.DataFrame(data)\n",
    "df\n",
    "df.mean()\n",
    "\n",
    "hmean(data['Maths'])\n",
    "\n",
    "from scipy.stats import gmean\n",
    "gmean(data['Maths'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8a176700",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StudentName</th>\n",
       "      <th>Maths</th>\n",
       "      <th>English</th>\n",
       "      <th>Science</th>\n",
       "      <th>History</th>\n",
       "      <th>Geography</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rama</td>\n",
       "      <td>56</td>\n",
       "      <td>77</td>\n",
       "      <td>66</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shama</td>\n",
       "      <td>67</td>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>radha</td>\n",
       "      <td>78</td>\n",
       "      <td>77</td>\n",
       "      <td>99</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dhara</td>\n",
       "      <td>89</td>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>arti</td>\n",
       "      <td>90</td>\n",
       "      <td>99</td>\n",
       "      <td>77</td>\n",
       "      <td>99</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>priti</td>\n",
       "      <td>56</td>\n",
       "      <td>66</td>\n",
       "      <td>66</td>\n",
       "      <td>66</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>sapna</td>\n",
       "      <td>67</td>\n",
       "      <td>45</td>\n",
       "      <td>88</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>komal</td>\n",
       "      <td>78</td>\n",
       "      <td>88</td>\n",
       "      <td>99</td>\n",
       "      <td>88</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>rima</td>\n",
       "      <td>89</td>\n",
       "      <td>77</td>\n",
       "      <td>88</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>neha</td>\n",
       "      <td>90</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  StudentName  Maths  English  Science  History  Geography\n",
       "0        rama     56       77       66       77         77\n",
       "1       shama     67       88       88       88         88\n",
       "2       radha     78       77       99       77         77\n",
       "3       dhara     89       88       88       88         88\n",
       "4        arti     90       99       77       99         99\n",
       "5       priti     56       66       66       66         66\n",
       "6       sapna     67       45       88       45         45\n",
       "7       komal     78       88       99       88         88\n",
       "8        rima     89       77       88       77         77\n",
       "9        neha     90       77       77       77         77"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "39f20dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Download any csv file of your choice and display details about data using pandas profiling. Show stats in HTML form.\n",
    "# pip install pandas-profiling\n",
    "# It can also be installed via Conda package manager too:\n",
    "# \n",
    "# conda env create -n pandas-profiling\n",
    "# conda activate pandas-profiling\n",
    "# conda install -c conda-forge pandas-profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6b1120ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas-profiling\n",
      "  Downloading pandas_profiling-3.6.6-py2.py3-none-any.whl (324 kB)\n",
      "Collecting ydata-profiling\n",
      "  Downloading ydata_profiling-4.6.4-py2.py3-none-any.whl (357 kB)\n",
      "Collecting statsmodels<1,>=0.13.2\n",
      "  Downloading statsmodels-0.14.1-cp39-cp39-win_amd64.whl (10.0 MB)\n",
      "Collecting imagehash==4.3.1\n",
      "  Downloading ImageHash-4.3.1-py2.py3-none-any.whl (296 kB)\n",
      "Collecting numba<0.59.0,>=0.56.0\n",
      "  Downloading numba-0.58.1-cp39-cp39-win_amd64.whl (2.6 MB)\n",
      "Requirement already satisfied: jinja2<3.2,>=2.11.1 in p:\\anaconda\\lib\\site-packages (from ydata-profiling->pandas-profiling) (2.11.3)\n",
      "Collecting dacite>=1.8\n",
      "  Downloading dacite-1.8.1-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: pandas!=1.4.0,<3,>1.1 in p:\\anaconda\\lib\\site-packages (from ydata-profiling->pandas-profiling) (1.3.4)\n",
      "Requirement already satisfied: matplotlib<3.9,>=3.2 in p:\\anaconda\\lib\\site-packages (from ydata-profiling->pandas-profiling) (3.4.3)\n",
      "Requirement already satisfied: numpy<1.26,>=1.16.0 in p:\\anaconda\\lib\\site-packages (from ydata-profiling->pandas-profiling) (1.20.3)\n",
      "Collecting phik<0.13,>=0.11.1\n",
      "  Downloading phik-0.12.4-cp39-cp39-win_amd64.whl (666 kB)\n",
      "Requirement already satisfied: tqdm<5,>=4.48.2 in p:\\anaconda\\lib\\site-packages (from ydata-profiling->pandas-profiling) (4.62.3)\n",
      "Collecting pydantic>=2\n",
      "  Downloading pydantic-2.5.3-py3-none-any.whl (381 kB)\n",
      "Collecting multimethod<2,>=1.4\n",
      "  Downloading multimethod-1.10-py3-none-any.whl (9.9 kB)\n",
      "Collecting htmlmin==0.1.12\n",
      "  Downloading htmlmin-0.1.12.tar.gz (19 kB)\n",
      "Collecting typeguard<5,>=4.1.2\n",
      "  Downloading typeguard-4.1.5-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: PyYAML<6.1,>=5.0.0 in p:\\anaconda\\lib\\site-packages (from ydata-profiling->pandas-profiling) (6.0)\n",
      "Requirement already satisfied: requests<3,>=2.24.0 in p:\\anaconda\\lib\\site-packages (from ydata-profiling->pandas-profiling) (2.26.0)\n",
      "Requirement already satisfied: seaborn<0.13,>=0.10.1 in p:\\anaconda\\lib\\site-packages (from ydata-profiling->pandas-profiling) (0.11.2)\n",
      "Collecting wordcloud>=1.9.1\n",
      "  Downloading wordcloud-1.9.3-cp39-cp39-win_amd64.whl (300 kB)\n",
      "Collecting visions[type_image_path]==0.7.5\n",
      "  Downloading visions-0.7.5-py3-none-any.whl (102 kB)\n",
      "Requirement already satisfied: scipy<1.12,>=1.4.1 in p:\\anaconda\\lib\\site-packages (from ydata-profiling->pandas-profiling) (1.7.1)\n",
      "Requirement already satisfied: PyWavelets in p:\\anaconda\\lib\\site-packages (from imagehash==4.3.1->ydata-profiling->pandas-profiling) (1.1.1)\n",
      "Requirement already satisfied: pillow in p:\\anaconda\\lib\\site-packages (from imagehash==4.3.1->ydata-profiling->pandas-profiling) (8.4.0)\n",
      "Requirement already satisfied: networkx>=2.4 in p:\\anaconda\\lib\\site-packages (from visions[type_image_path]==0.7.5->ydata-profiling->pandas-profiling) (2.6.3)\n",
      "Collecting tangled-up-in-unicode>=0.0.4\n",
      "  Downloading tangled_up_in_unicode-0.2.0-py3-none-any.whl (4.7 MB)\n",
      "Requirement already satisfied: attrs>=19.3.0 in p:\\anaconda\\lib\\site-packages (from visions[type_image_path]==0.7.5->ydata-profiling->pandas-profiling) (21.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in p:\\anaconda\\lib\\site-packages (from jinja2<3.2,>=2.11.1->ydata-profiling->pandas-profiling) (1.1.1)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in p:\\anaconda\\lib\\site-packages (from matplotlib<3.9,>=3.2->ydata-profiling->pandas-profiling) (3.0.4)\n",
      "Requirement already satisfied: cycler>=0.10 in p:\\anaconda\\lib\\site-packages (from matplotlib<3.9,>=3.2->ydata-profiling->pandas-profiling) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in p:\\anaconda\\lib\\site-packages (from matplotlib<3.9,>=3.2->ydata-profiling->pandas-profiling) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in p:\\anaconda\\lib\\site-packages (from matplotlib<3.9,>=3.2->ydata-profiling->pandas-profiling) (1.3.1)\n",
      "Requirement already satisfied: six in p:\\anaconda\\lib\\site-packages (from cycler>=0.10->matplotlib<3.9,>=3.2->ydata-profiling->pandas-profiling) (1.16.0)\n",
      "Collecting numpy<1.26,>=1.16.0\n",
      "  Downloading numpy-1.25.2-cp39-cp39-win_amd64.whl (15.6 MB)\n",
      "Collecting llvmlite<0.42,>=0.41.0dev0\n",
      "  Downloading llvmlite-0.41.1-cp39-cp39-win_amd64.whl (28.1 MB)\n",
      "Requirement already satisfied: pytz>=2017.3 in p:\\anaconda\\lib\\site-packages (from pandas!=1.4.0,<3,>1.1->ydata-profiling->pandas-profiling) (2021.3)\n",
      "Requirement already satisfied: joblib>=0.14.1 in p:\\anaconda\\lib\\site-packages (from phik<0.13,>=0.11.1->ydata-profiling->pandas-profiling) (1.1.0)\n",
      "Collecting pydantic-core==2.14.6\n",
      "  Downloading pydantic_core-2.14.6-cp39-none-win_amd64.whl (1.9 MB)\n",
      "Collecting annotated-types>=0.4.0\n",
      "  Downloading annotated_types-0.6.0-py3-none-any.whl (12 kB)\n",
      "Collecting typing-extensions>=4.6.1\n",
      "  Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in p:\\anaconda\\lib\\site-packages (from requests<3,>=2.24.0->ydata-profiling->pandas-profiling) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in p:\\anaconda\\lib\\site-packages (from requests<3,>=2.24.0->ydata-profiling->pandas-profiling) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in p:\\anaconda\\lib\\site-packages (from requests<3,>=2.24.0->ydata-profiling->pandas-profiling) (1.26.7)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in p:\\anaconda\\lib\\site-packages (from requests<3,>=2.24.0->ydata-profiling->pandas-profiling) (2.0.4)\n",
      "Collecting numpy<1.26,>=1.16.0\n",
      "  Downloading numpy-1.22.4-cp39-cp39-win_amd64.whl (14.7 MB)\n",
      "Collecting patsy>=0.5.4\n",
      "  Downloading patsy-0.5.6-py2.py3-none-any.whl (233 kB)\n",
      "Collecting packaging>=21.3\n",
      "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
      "Requirement already satisfied: colorama in p:\\anaconda\\lib\\site-packages (from tqdm<5,>=4.48.2->ydata-profiling->pandas-profiling) (0.4.4)\n",
      "Requirement already satisfied: importlib-metadata>=3.6 in p:\\anaconda\\lib\\site-packages (from typeguard<5,>=4.1.2->ydata-profiling->pandas-profiling) (4.8.1)\n",
      "Requirement already satisfied: zipp>=0.5 in p:\\anaconda\\lib\\site-packages (from importlib-metadata>=3.6->typeguard<5,>=4.1.2->ydata-profiling->pandas-profiling) (3.6.0)\n",
      "Building wheels for collected packages: htmlmin\n",
      "  Building wheel for htmlmin (setup.py): started\n",
      "  Building wheel for htmlmin (setup.py): finished with status 'done'\n",
      "  Created wheel for htmlmin: filename=htmlmin-0.1.12-py3-none-any.whl size=27098 sha256=20c6acf84b1dc5b2b4c930c6b5f2966458980496ea60d1a4709e92febbd7c477\n",
      "  Stored in directory: c:\\users\\lenovo\\appdata\\local\\pip\\cache\\wheels\\1d\\05\\04\\c6d7d3b66539d9e659ac6dfe81e2d0fd4c1a8316cc5a403300\n",
      "Successfully built htmlmin\n",
      "Installing collected packages: numpy, typing-extensions, tangled-up-in-unicode, multimethod, visions, pydantic-core, patsy, packaging, llvmlite, imagehash, annotated-types, wordcloud, typeguard, statsmodels, pydantic, phik, numba, htmlmin, dacite, ydata-profiling, pandas-profiling\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.20.3\n",
      "    Uninstalling numpy-1.20.3:\n",
      "      Successfully uninstalled numpy-1.20.3\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing-extensions 3.10.0.2\n",
      "    Uninstalling typing-extensions-3.10.0.2:\n",
      "      Successfully uninstalled typing-extensions-3.10.0.2\n",
      "  Attempting uninstall: patsy\n",
      "    Found existing installation: patsy 0.5.2\n",
      "    Uninstalling patsy-0.5.2:\n",
      "      Successfully uninstalled patsy-0.5.2\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 21.0\n",
      "    Uninstalling packaging-21.0:\n",
      "      Successfully uninstalled packaging-21.0\n",
      "  Attempting uninstall: llvmlite\n",
      "    Found existing installation: llvmlite 0.37.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Cannot uninstall 'llvmlite'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas-profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aba9451e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas_profiling'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_2444/4001871067.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mpandas_profiling\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mProfileReport\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprofile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mProfileReport\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprofile\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'pandas_profiling'"
     ]
    }
   ],
   "source": [
    "from pandas_profiling import ProfileReport\n",
    "profile = ProfileReport(df)\n",
    "profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5377460e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
